
ConcurrentHashMap 1.8
    
    读写;  https://blog.csdn.net/ZOKEKAI/article/details/90741157?spm=1001.2014.3001.5501
    lastRun  https://copyfuture.com/blogs-details/20200401011041767qy9vhjshgdbvtge
    扩容   https://blog.csdn.net/ZOKEKAI/article/details/90051567

    状态 SizeCtl 0 未初始化
                 -1 正在初始化
                 <-1  正在扩容 有 -(n+1)个线程正在扩容
                 >0 数组没初始化记录数组容量 数组初始化了记录扩容阈值
    
    
    初始化：（第一次put执行）
        判断 SizeCtl -1 如果正在初始化 让出线程
        二次检索判断状态 都没有初始化 则进行初始化 
    
    计算位置：
        (n - 1)&hash n为容量

    put:
        1.首先计算hash值
        2.然后判断是否初始化 没有则初始化（cas 初始化 只能有一个线程抢到初始化的锁 的权限 剩下的继续循环）
        3.判断 桶有没有值 没发生hahs碰撞 则直接新建一个Node节点 通过CAS设置
        4.如果正在扩容fwd  则协助扩容 
        5.如果发生碰撞 先锁头元素 sync 然后如果是链表 循环查找 找到更新 找不到尾部追加 然后用bitCount记录 链表数量
                                          如果是树 执行树的添加 树平衡会尝试获取写锁
                                          然后检查 bitcount >8 总数量 >64 链表变树
        6.然后进行数据 +1 addCount 查看是否足要扩容

        补充：
            1.非扩容 执行添加 判断
            2.在扩容 添加的位置 是 fwd  协助扩容
                     添加的位置 正在扩容的桶 就阻塞
                     添加的位置 还没扩容 就正常添加
        
        
    
    扩容:transfer （fwd 为 hash值等于 -1 的Node） transferIndex 就是剩余的桶数量
        1.协助扩容 讲 length/8/cpu数  如果小于16 那就使用16   如果桶很少就一个cpu扩容 （协助扩容也有上限 transferIndex = 0就没桶分了）
        2.创建一个数组长度为原来两倍

        3.开始扩容 首先分配任务 每个线程分配最少16的任务 然后扩容 扩容完毕继续回来领取任务 直到扩容完毕或没有任务可以分配
             3.1 如果是链表 找到lastRun节点 找的过程：循环链表 设置标志位先记录头结点 然后如果循环的节点 hash&旧长度 和 头结点 不同
                                                     把标志位替换成 这个不同的节点 然后依次循环 这样标志位记录的就是 最后一个不同的节点
                                                    也就是说 从标志位节点开始到尾节点 hash&旧长度 都相同，将来分高低链表都直接分一块。
                            创造两个链表 高位链表 低位链表 （复制出来的 这时候读会读原链表 ）
                            然后循环链表 从头开始到 lastRun 会根据 hash&旧长度 判断分到高位链表还是低位链表 然后使用头插法插入
                            循环到lastRun后面直接全部添加 不用再消耗资源。
                            完事设置fwd节点
            3.2 如果是树 使用链表的方式遍历树 然后也是使用高位低位链表 然后采用尾插法插入（和链表不同 链表扩容是头插）
                        然后还会判断 新的高位链表 地位链表长度是否大于8 大于树化 不大于就不大于。

        4.根据SizeCtl判断是否除了自己所有线程都结束工作，如果自己是最后一个工作线程，扩容完毕后会进行检查操作，从头到尾检查一遍
          是否有没不是fwd的节点，有的话再迁移到新数组中。因为是并发操作可能额外有新的值添加进来或漏掉了。

        补充：
            1.只有 put(),remove() fwd 的Node 才会触发协助扩容
            2.get() 无论是没迁移，迁移中，还是迁移完毕fwd 读都不受影响
            3. 正在迁移中 执行put() remove() 会被阻塞 因为加了synchronized



    addCount 修改计数： put remove 都用这个
        一个变量 baseCount 一个数组 counterCells[] 

        1. 如果数组没初始化 在basecount 执行 cas添加
        2. cas失败 竞争失败的线程会执行fullAddCount死循环,执行到数组初始化部分 初始化数组长度为2计算 Hash 在数组的位置(该值和线程值求与）
           如果数组的位置没有值，并且获取标志位成功，则初始化桶位放这个值，如果桶位有值则尝试CAS修改
        3. 添加到数组失败会再次尝试 两次失败会扩容 counterCells[] 数组 初始容量为 2 最大不超cpu核数，扩容每次*2 扩容后原来数据在哪还在那
        4. 如果数组为空 长度为0 则尝试 cas baseCount

        5.如果数组初始化了 就不会再修改 baseCount了 都对数组进行操作了。
        6。修改完数值后，判断节点数是否超过阈值，超过就进入扩容操作
    
    get():
        get操作全程不需要加锁是因为Node的成员val是用volatile修饰的
        三种情况：
        (1) 非扩容情况下：遇到 get 操作，通过计算 (n - 1) & h 定位到具体的hash桶位置，如果数组上的hash桶就是目标元素则直接返回即可 。
            如果当前hash桶为普通Node节点链表，则使用普通链表方式去遍历该链表查找目标元素 。如果定位到的hash桶为TreeBin节点，则根据
            TreeBin内部维护的红黑树锁来确定具体采用哪种方式遍历查找元素，如果如果红黑树锁的状态为 写锁 / 等待写锁，则使用链表方式去
            遍历查找目标元素，而反之红黑树锁状态为 无锁 / 读锁，则使用红黑树方式去遍历查找目标元素，红黑树锁只存在 读-写 互斥而不存在
             写-写 ，写-读 互斥 。

        (2) 集合正在扩容并且当前hash桶正在迁移中：遇到 get 操作，在扩容过程期间会形成 hn 和 ln链，形成这两条中间链是使用的类似于复制
            引用的方式，也就是说 ln 和 hn 链是复制出来的，而非原hash桶的链表剪切过去的，所以原来 hash 桶上的链表并没有受到影响，因此
            从迁移开始到迁移结束这段时间都是可以正常访问原数组 hash 桶上面的链表，具体访问方式同上面的 (1) 点 。

        (3) 集合扩容还未结束但是当前hash桶已经迁移完成：遇到 get 操作，每迁移完一个hash桶后当前hash桶的位置都会被替换成 ForwardingNode
            节点，遇到 get 操作时直接将查找操作转发到新的数组上去，也就是直接到新数组上面查找目标元素，具体的查找方式依旧跟上面的 (1) 
            点相同 。
        
       （4） 如果是正在读树，然后尝试写操作，就会阻塞。
    
    树：
        树hash值为-2
        树有自己的状态标志  lockstate 默认值 0
                        1 ----- 写锁 （平衡红黑树才会加锁，普通写不会加锁）
                        2 ----- 写等待（尝试加写锁被阻塞正在等读操作释放锁 只能有一个线程获取写等待锁）
                        4 ----- 读锁
        
        树里只有读写互斥 写写 读读不互斥

        正在写 可以读 链表方式读
        正在读 不可以写 会.unpark 释放因为获取不到写锁阻塞的线程（不是等待锁持有的线程）

            读中有多个写操作进来：阻塞
        
        加写锁：（树平衡加）
            在树进行平衡操作时才睡进行加写锁
            设置写锁 lockstate
            尝试 cas 设置为写锁
            失败尝试 设置为等待写锁
            再失败继续循环 如果还不可以设置为等待写锁 或 写锁 执行 LockSupport.park() 阻塞，然后 unpark() 操作在读锁释放中进行

        写：
            根据hash值 小找左 大找右 找到红黑树位置，判断是替换还是新增，然后判断是否平衡进行平衡操作


    fwd:
        hashCode = -1 Node节点
        提供find（） 读fwd节点时会跳转到新的map中取读取
        写fwd 会协助扩容


HashMap 1.8

    put：
        1.如果是空直接 new Node
        2.如果冲突 新建临时Node e 记录冲突
            树冲突 查找那个位置冲突 没就更新
            链表冲突 便利链表 有就记录 没有就尾部插入 链表判断是否 > 8变树
            头冲突 记录头
        3.替换 e 冲突的 值 吧原来值覆盖 返回原来的值
        4.判断是否扩容
    
    扩容机制：
        1.先构建新的数组 长度 *2  相应的阈值也进行设置
        2.创建两个链表 接收高低位 从头到尾开始便利
        3.计算 链表的每一个值 进行hash值 oldsize 与运算 区分高低位 看在新数组的位置是原来的位置 还是原来 + 原数组长度的位置
        4.返回新的数组

    树扩容：
        也会进行高低位判断 然后也是构造高低位链表 因为TreeNode 继承LinkedHashMap 所以有链表的next指针
        便利完毕 高低位链表进行完存储后会进行判断 判断如果小于6就变成链表 大于6还是红黑树


    不安全的原因：
        在hashmap做put操作的时候会调用到以上的方法。现在假如A线程和B线程同时对同一个数组位置调用addEntry，两个线程会同时得
        到现在的头结点，然后A写入新的头结点之后，B也写入新的头结点，那B的写入操作就会覆盖A的写入操作造成A的写入操作丢失

        当多个线程同时检测到总数量超过门限值的时候就会同时调用resize操作，各自生成新的数组并rehash后赋给该map底层的数组
        table，结果最终只有最后一个线程生成的新数组被赋给table变量，其他线程的均会丢失。而且当某些线程已经完成赋值而其他
        线程刚开始的时候，就会用已经被赋值的table作为原始数组，这样也会有问题。

        https://www.zhihu.com/question/28516433   多个线程扩容数据丢失

依赖查找





