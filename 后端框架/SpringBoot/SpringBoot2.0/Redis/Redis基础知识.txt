https://blog.csdn.net/qq_32448349/article/details/101696892
https://www.cnblogs.com/ejiyuan/p/11014765.html

Redis安装：https://www.cnblogs.com/liuqingzheng/p/9831331.html
Redis命令大全：http://redisdoc.com/

缓存  不同于数据库 读取更快 临时文件可以放在缓存中
Redis启动： cd c:\program files\redis
            redis-cli
            auth 12345


Jedis 
        java 操作Radis得工具
        maven 导入：
                <dependency>
                        <groupId>redis.clients</groupId>
                        <artifactId>jedis</artifactId>
                        <version>2.9.0</version>
                </dependency>
        操作：
                获取连接：             Jedis jedis = new Jedis("127.0.0.1",6379);
                设置密码：             jedis.auth("12345");
                返回连接结果：         System.out.println(jedis.ping());

                提交Hash
                        HashMap<String, String> map = new HashMap<>();
                        map.put("name","李四");
                        map.put("age","12");
                        map.put("inf","aaaa");
                        jedis.hmset("person2",map);
                事务执行： 
                         //设置事务
                        Transaction multi = jedis.multi();
                        //事务的提交
                        multi.set("str011","1");
                        multi.set("str0111","1");
                        multi.set("str01111","1");
                        //提交
                        multi.exec();

                主从复制：
                        jedis.slaveof("127.0.0.1",6379);
               
                JedisPool:
                         //池子的使用
                        //建立对象
                        Jedis jedis1 = null;
                        //获取池子
                        JedisPool pool = JedisPoolUtil.getJedisPool();
                        //获取连接
                        try {
                        jedis1 = pool.getResource();
                        } catch (Exception e) {
                        e.printStackTrace();
                        } finally {
                        //退回给池子
                        JedisPoolUtil.release(pool,jedis1);
                        }



                        //单例
                        class JedisPoolUtil{
                        private static volatile JedisPool jedisPoolutil = null;
                        private  JedisPoolUtil (){};
                        //实例化
                        public static JedisPool getJedisPool(){
                                if(jedisPoolutil == null){
                                synchronized (JedisPoolUtil.class){
                                        if(jedisPoolutil == null){
                                        //jedis 池配置 保证返回的永远是一个池
                                        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
                                        //最大连接数  老版本是setMaxActive
                                        jedisPoolConfig.setMaxTotal(1000);
                                        //最多空闲数
                                        jedisPoolConfig.setMaxIdle(32);
                                        //最大等待时间 毫秒
                                        jedisPoolConfig.setMaxWaitMillis(100*1000);
                                        //获取Redis示例时是否检查可用性
                                        jedisPoolConfig.setTestOnBorrow(true);


                                        jedisPoolutil = new JedisPool(jedisPoolConfig,"127.0.0.1",6379);
                                        }
                                }
                                }


                                return jedisPoolutil;
                        }
                        //执行退回 池子的东西用完了还要退回去  退回哪个池子那个对象
                        public static void release(JedisPool jedisPool,Jedis jedis){
                                //不是空再执行
                                if(null != jedis){
                                //这里close() 代替了  jedisPool.returnBrokenResource();
                                //关闭连接
                                jedis.close();
                                }
                        }

                        }

Redis:
        聚合模型：
                KV对
                Bson 类似Json  文档存储
                列族
                图形

       传统数据库ACID   :A Atomicity 原子性
                        C Consistency 一致性
                        I Isolation 独立性
                        D Durability 持久性

       NoSQL数据库  CAP:  C Consistency 强一致性  
                          A Availability 可用性
                          P Paration tolerance 分区容错性   （重要）


                        CAP只能三选二 三个特点不可能都满足，一个分布式系统不可能同时满足C,A,P这三个需求，最多只能完成两个 

                        CA : 单点集群，满足一致性，可用性得系统，通常在可扩展性不太强大   RDBMS  Oracle
                        CP:  满足一致性，分区容错性，通常性能都不好           MongoDB HBase Redis
                        AP: 满足可用性，分区容错性得系统，一致性都不好   大多数选择  数据量太大不能保证一致性  memcached 集群Redis



        设置Redis 密码：config set requirepass “密码”
        默认端口号 6379 
        进入Redis 目录： cd C:\Program Files\Redis
        启动Redis redis-cli
        输入密码  auth 12345   //设置密码未12345
        Redis 单进程 
        默认16个数据库  通过select num 选择   库得下标是 0-15  初始默认选择得是0号
                        e.g. 选择第一个库 select 1   显示： 127.0.0.1:6379[1]>

        Redis命令： -1 下标代表到所有
                  
            Key：
                set 名字 "内容"         设置key  set mykey1 "I love you all!”   如果有此Key 再次执行时会覆盖原来的值
                get 名字                获取key  get mykey1
                select  Num             选择第num 个库 0<num<15
                dbsize                  获取此库中 key得数量
                flushdb                 清空当前库
                flushall                清空所有库
                del keyname             删除key
                keys *                  查看此库所有的 key
                keys m?                 查找所有m开头得key 例如 m1,m2,mmm
                exists m                查找此库中是否有这个key 
                expire keyname m        给指定的key(keyname) 设定存活秒数
                ttl keyname             查看还有多久过期  -1 表示永不过期 -2表示已经过期
                type keyname            查看你的key是什么类型得     

            String:
            
            
                append keyname str      对keyname 后面追加字符串 str
                strlen  keyname         查看指定String 类型 key 得长度
                incr keyname            指定keyname +1  必须是数字 否则会报错
                incrby keyname num      指定keyname + num  必须是数字 否则会报错
                decr keyname            指定keyname -1  必须是数字 否则会报错
                decrby keyname num      指定keyname - num  必须是数字 否则会报错
                getrange keyname num1 num2   获取指定keyname 得 num - num1 范围（左右都闭） 得内容  
                                            e.g.  set k1 = "abc123" getrange k1 0,-1  -> abc123   getrange k1 0,3  -> abc1 
                setrange keyname num1 str   设置指定keyname 得 num 位置开始 值为str 后面如果有值就替换 
                                            e.g.   set k1 = "abc123"  setrange k1 1 mmm  -> ammm23
                setex  keyname s str    设置keyname 存活s 秒 值为 str 
                setnx keyname value     如果keyname不存在 就新建设置值为value 如果存在就不做操作
                mset k1 v1 k2 v2  ..    同时设置多个 key,value
                mget k1 k2 k3  ...      同时获取多个key    
                msetnx k1 v1 k2 v2...   同时设置多个k v 如果多个key 都不存在则成功，有一个存在所有的都失败
                                        e.g. set k1 v1  msetnx k1 v2 k2 v2  -> (integer) 0     失败  因为k1 存在 则此次存的所有值都存不进去
                                             set k1 v1  msetnx k2 v2 k3 v3  -> （Integer）1 成功 
        
        ***  Hash:集合  *** 可以映射对象
                hset mapname k v    新建（存在则更新） mapname 值得键位 k  值得值为 v
                                        e.g. hset user age 11
                hget mapname k      获取 mapname 中 键为k 得值
                                        e.g. hget user age - > 11
                hmset mapname k1 v1 k2 v2 k3 v3    新建（存在则更新） mapname 多个 键值信息
                hmget mapname k1 k2 k3..           获取多个k值对应的v值
                hgetall mapname                    获取所有的k值对应得v值
                hdel mapname k                     删除指定map下得指定key  
                hlen mapname                       返回这个hash得长度
                hexists mapname k                   查找mapname里是否包括 指定key
                hkeys mapname                      查找mapname下所有的key
                hvals mapname                      查找mapname下所有的value
                hincrby mapname k num              给mapname得k属性得 v + num (num 为 int)
                hincrbyfloat mapname k num         给mapname得k属性得 v + num (num 为 float)
                hsetnx mapname k v                 给mapname设置k属性如果存在就不设置不存在再设置

            List：  链表
                lpush  listname1 n1 n2 n3 n4 n5      创建(存在则添加)一个Stack filo 式链表 名字为 listname 值为n1 n2 n3 n4 n5   
                rpush  listname2 n1 n2 n3 n4 n5      创建(存在则添加)一个Queue fifo 式链表 名字为 listname 值为n1 n2 n3 n4 n5
                lrange listname start end           遍历集合listname start为开始下标 end 为结束下标 end 为 -1 就是遍历剩下所有 
                                                  e.g. 遍历 lpush 时是 n5 n4 n3 n2 n1 rpush 是 n1 n2 n3 n4 n5
                lpop listname          删除并显示链表顶部数字
                                        e.g. lpop listname1 -> n5   lpop listname2 -> n1
                rpop listname          删除并显示链表底部数字      
                                         e.g. rpop listname1 -> n1   rpop listname2 -> n5 
                                
                lindex listname index   查找 listname 链表下 下标 index 得元素
                llen  listname          返回链表长度 
                lrem listname  num value   删除listname得 num个值为value 得元素
                                        e.g. rpush list3 1 1 1 2 3 4 5 6 lrem list3 3 1 //删除3个1 -> lrange list3 -> 2 3 4 5 6
                ltrim listname start stop 截取list1 从start下标开始到stop得元素,清空listname所有得值，并把截取得元素重新赋值给listname
                                        e.g. rpush list3 1 2 3 4 5 6 l  trim list3 3 4  ->    lrange list3 ->  4 5
                rpoplpush listfrom listto 截取 listfrom 最后一个元素到 listto 第一个上
                                        e.g. rpush list1 1 2 3
                                             rpush list2  10 11 12
                                             rpoplpush list1 list2 ->   lrange list1  -> 1 2 
                                                                        lrange list2   -> 3  10 11 12
                lset listname index value  设置Listname 得index 位置元素值为value
                                        e.g.   rpush list1 1 2 3 lset list1 1 haha  -> 1 haha 3
                linsert listname before/after index num   在listname index 位置元素前/后插入 元素 num
                                         e.g.   rpush list1 1 2 3  linsert list1 before 1 fff -> 1 fff 2 3 
            
            Set:集合（不允许重复）
                sadd setname s1 s2 s3...   新建(存在则添加)set 集合 setname 值为 s1,s,s3.. 如果有重复值会自动删除
                                        e.g. sadd set1 1 1 1 2 2 2 3 -> smembers set1-> 1 2 3
                smembers setname      显示setname 得所有元素
                sismenbers setname s      查找 元素 s是否在集合 setname中
                scard setname           获取setname 集合元素个数
                srem setname s          删除 setname 中 值为s得元素（注意不是下标）
                srandmember setname num 从setname中随机选择num个元素并返回（不删除）
                spop setname          随机删除一个元素，并显示这个元素
                smove setname1 setname2 num 把setname1中 num（这个值必须在setname1中） 添加到setname2得末尾上
                                        e.g. sadd set1 a b c 
                                             sadd set2 1 2 3
                                             smove set1 set2 a -> smembers set2 1 2 3 a
                                                               -> smembers set1 b c
                sdiff set1 set2      查找在set1 不在sert2得元素
                                        e.g. sadd set1 1 2 3 4 5 
                                             sadd set2 1 2 3 a b 
                                             sdiff set set2 -> 4 5
                sinter set1 set2      查找set1 set2得交集
                sunion set1 set2      查找set1 set2得并集
              
        Zset:有序集合（内容不允许重复,score可以重复）
                zset就是在之前得set基础上加一个score值
                //set setname k1 k2 k3
                zadd zsetname score1 k1 score2 k2 score3 k3  

                zadd zsetname score1 k1 score2 k2 score3 k3     设置zsetname score1 k1 ..属性  
                                        e.g. zadd zset1 60 k1 70 k2
                zrange zsetname start stop      遍历zsetname 
                                        e.g.    zrange zset1 0 -1 -> k1 k2
                zrange  zsetname start stop withscores  遍历出所有k 和score
                                        e.g.  zrange zset1 0 -1 withscores -> k1 60 k2 70
                zrangebyscore zsetname startscore stopscore 在zsetname中查找出score范围在 startscore - stopscore 中得值
                                       （ 为不包含  （startscore 为不包含startscore
                                       limit  对结果集进行截取
                zrem zsetname k       根据k值删除对应的k和score值
                zcard zsetname        获取集合元素数量
                zcount zsetname startscore stopscore   统计指定score区间内个数
                zranke zsetname k                      获取指定元素排名 小到大
                zscore zsetname k                      获取指定k得score值
                zrevrange zsetname start stop           获取指定元素排名 大道小
                zincrby   增加


        bitmap:   string                
                setbit getbit bitcount bittop (两个bitmap位置映射)
        hyperloglog   string
                pfadd pfcount 
        geo:  zset
                geoadd geopos（返回坐标） geohash(返回hash) georadius（给定坐标附近）  可以用zset zrange 便利
                                      




        Redis 五大数据类型：
                        String 字符串
                        Hash 哈希，类似Java 里得map
                        List 列表
                        Set 集合
                        Zset 有序集合      

                String 类型：是Redis 最基本的类型 一个key对应一个value
                        String 类型是二进制安全的。意思是Redis得String 可以包含任何数据。比如jpg图片或者序列化得对象
                        一个Redis 中字符串得value 最多可以存储512M
                
                Hash 类型：  Redis hash 是一个键值对得集合
                        Redis hash 是一个String 类型得field 和value 得映射表，hash特别适合用于存储对象
                        类似 Map<String,Object>
                
                List类型：   Redis列表是简单的字符串列表，按照插入顺序存储，你可以添加一个数据在链表头部得左边或者尾部得右边 
                        类似 LinkedList
                
                Set类型：    Redis得set是String类型无序集合，通过HashTable实现得 （不允许重复）

                Zset类型：   Redis得zset和set 一样也是String类型得元素集合，且不允许有重复得成员，不同的是 zset是有序得
                        有序是通过每一个元素都会关联一个double 类型得分数，Redis通过分数为集合中得元素从小到大进行排列，
                        zset得成员是唯一的，但分数可以重复
        

        Redis持久化：

                 RDB: Redis DATABASES 
                 AOF: Append only File
                 rdb aof都存在时首先备份查找aof


                 RDB：  
                        ########SNAPSHOTTING
                        rdb是整个内存的压缩过程的Snapshot ,RDB的数据结构，可以配置复合快照触发条件 (就是隔一段时间自动备份一次数据)，
                        rdb是一个非常紧凑的文件
                        rdb工作过程：
                                  复制出一份完全一模一样的子进程，所有rdb工作都由子进程来做，父进程不需要做任何IO操作，子进程根据默认
                                  规则定时备份，备份到磁盘里drum.rdb文件中，这样性能很好，效率高，不过数据丢失风险大（一边操作一遍备份）
                        坑： 执行flushall数据大时也会执行 就可能回复失败，所以需要额外备份

                        优势：适合大规模数据的恢复，对数据完整性一致性要求不高
                        劣势：在一定间隔时间做一次备份，所以如果Redis意外Down时候，就会丢失下最后一次快照的所有的修改
                              复制的时候，内存中的数据被克隆一份，大致两倍膨胀性需要考虑

                        默认文件：dump.rdb
                        默认自动备份规则：
                                1分钟内修改一万次
                                或 5分钟内修改10次
                                或 1分钟内修改了一次

                                就开启默认备份
  
                        禁用： save ""  
                        常用命令：
                                save   立刻执行备份
        

                 AOF:
                        工作过程：以日志的形式来记录每一个写操作，将Redis执行过的所有指令写下来（读 get 操作不进行记录），只追加文件但不改写文件，
                                 redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据恢复
                                 最小误差 1s
                        默认文件名：appendonly.aof
                        坑： 如果执行Flushall aof也会默认记录下来，所以恢复时候也会执行flushall的操作，必须干掉flushall才可以   
                        修复： rdb aof同时存在并且aof文件有错误有乱码时：执行redis-check-aof 进行修复   
                
                        配置位置： appendonly no 默认 
                                   appendonly yes 打开aof持久化    
                        配置策略：Appendfsync :Always 同步持久化 每次数据发生变化会被立刻执行记录到磁盘，性能差但是数据完整性好
                                              Everysec 默认设置，每秒记录一次
                                              nO 不同步
                        Rewrite:
                                是什么：aof采用文件追加方式记录数据，这样文件会越来越大，为了避免这种情况，新增了重写机制，
                                        当aof文件大小超过所设定的阀值时，Redis就会启动ROF文件压缩，只保留可以恢复数据的
                                        最小指令集，可以使用命令bgrewriteaof
                                工作过程：aof问价持续增长时，会foke一条新的进程来将文件重写，先临时写再rename，遍历新的进程的内存数据，
                                        每条记录会有一条set语句。重写aof的操作不是直接读取旧的aof而是将整个所有的数据用命令的方式重写了一个
                                        新的aof文件，这个快照有点相似
                                触发机制：默认配置是当aof文件大小是上次rewrite大小的一倍且文件大于64m时触发

                                no-appendfsync-on-rewrite 重写时是否可以运用appendfsync 默认no 
                                auto-aof-rewrite-min-size:设置重写基准值
                                auto-aof-rewrite-percentage:设置重写基准值
                        优势：同步数据更好，数据完整性更好      
                        劣势：要存储的数据量远远大于rdb,运行效率比rdb慢
                
        Redis事务：
                命令：mulit     标记事务开始
                     discard    取消事务，放弃执行事务内的所有命令
                     exec       执行所有事务块的命令（提交事务）
                     Unwatch    取消watch命令的监视
                     watch key ..  监视一个或多个key,如果事务执行之前这些（一个或多个）key被其他命令改动，那么事务会被打断 类似CAS 

                事务执行：
                        multi              开始
                        ...                若干redis操作语句
                        exec/discard       提交/放弃提交
                事务特性：
                        全体连坐，错一个都不提交（指redis命令语句就是有问题 比如打一堆乱码）
                        不保证原子性无回滚：单独针对，对的放行（编译阶段redis语句都没有问题，执行exec时发现问题例如incr一个字符串 这时除了incr这儿命令，其他正确的都可以提交）
                        没有隔离级别

        Reids主从复制：
                用法：配从库不配主库
                从库配置：
                        SLAVEOF 主库ip 主库端口  SLAVEOF 连接，除非写进了配置文件
                        SLAVEOF no one   从 从机变主机

                        info replication 查看当前redis信息，连接状态  主库master 从库 slave

                 读写分离 从机没有写的权限

                 复制原理：
                        Slave启动成功后连接到master 会发送一个sync命令 （同步命令）
                        master接到命令启动后台后台存盘进程，同时接收收集所有的用于修改数据的命令，再后台进程执行完毕后，master将传送整个数据文件
                        到slave,完成一次同步

                        全量复制：刚启动时将master所有数据全部加载复制
                        增量复制：建立连接后，进行全量复制后，开始进行增量复制只记录增加的部分，但是要是断开连接重连，还要进行一次全量复制
                
                
                
                哨兵模式：
                        主库死亡不用再手动选定新主库，由Redis从库通过投票选出来
                        https://w ww.jianshu.com/p/06ab9daf921d

        

                Linux：  192.168.40.129:6379
                        密码： 12345
                        默认位置 /usr/local/bin 
                        文件位置 /opt
                        redis.conf 位置   /etc
                                         /opt/redisconf/

                        /usr/local/bin

                                redis-benchmark 性能测试工具
                                redis-check-aof 修复有问题的aof
                                redis-check-dump 修复有问题的dump.rdb
                                redis-sentinel   redis集群使用
                                redis-server     redis服务器启动命令
                                redis-cli -p 6379       客户端入口
                        
                        启动:
                                cd /usr/local/bin
                                redis-server /opt/redisconf/redis.conf
                        
                        设置后台启动：
                                #########GENERAL  模块

                                daemonize yes    //默认 no 不启用后台启动
                        
                        查看本机redis信息命令：   info replication
                        哨兵： 6379 6380 6381 
                           1.首先 启动    redis-server /opt/redisconf/redis.conf6379
                                        redis-server /opt/redisconf/redis.conf6380
                                        redis-server /opt/redisconf/redis.conf6381

                                        从机需要配置密码 masterauth 12345  （写在配置文件中）

                                再进入cli    redis-cli -p 6379   / redis-cli -h 192.168.40.129 -p 6379 -> 这是配置了bind 192.168.40.129启动方法
                                输入密码     auto 12345
                                给6380 6381设置主机  SLAVEOF 127.0.0.1 6379

                           2.在/opt/redisconf 下新建 sentinel.conf 文件   touch sentinel.conf

                                写入信息：
                                        sentinel monitor 自己起的名字 ip 端口号 票数

                                        sentinel monitor host6379 127.0.0.1 6379 1    //端口
                                        sentinel deny-scripts-reconfig yes
                                        sentinel auth-pass host6379 12345        //密码

                           3.启动哨兵
                                 cd /usr/local/bin      redis-sentinel /opt/redisconf/sentinel.conf

                                 成功提示：   @后面得是主机名 端口号   这里就是host6379 127.0.0.1 6379
                                        14838:X 17 May 2021 21:59:22.573 # Sentinel ID is 535b9876982d1cdc0e4a9594b313e05275d76875
                                        14838:X 17 May 2021 21:59:22.573 # +monitor master host6379 127.0.0.1 6379 quorum 1
                                        14838:X 17 May 2021 21:59:22.575 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ host6379 127.0.0.1 6379
                                        14838:X 17 May 2021 21:59:22.576 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ host6379 127.0.0.1 6379
                          4.搞破坏：
                                让6379 master 关机，在等待一会，不一会就选出新领导人了
                

                        集群：  
                                无中心化集群配置：
                                        redis集群实现了对redis进行水平化扩容，即启动了N个节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据得1/N

                                实现：  
                                        开启daemonized yes 
                                        修改pid    
                                        修改port
                                        修改 dbfilename
                                        增量:
                                                cluster-enabled yes                       打开集群模式
                                                cluster-config-file nodes-6379.conf      设置节点配置文件名
                                                cluster-node-timeout 15000               设置节点失联时间，超过该时间，集群自动进行主从切换

                                                cluster-enabled yes                       
                                                cluster-config-file nodes-6379.conf      
                                                cluster-node-timeout 15000               


                                         合体：  （要把每一个redis得所有东西都删除 flushall ）
                                                cd /opt/redis-6.2.1/src 
                                                执行命令：  这里的1是一个主机配一个从机得意思
                                                        redis-cli --cluster create --cluster-replicas 1 192.168.40.129:6379  192.168.40.129:6380 192.168.40.129:6381 192.168.40.129:6389 192.168.40.129:6390 192.168.40.129:6391
 
                                         启动集群：
                                                启动集群中任意一个节点就可以连接到集群
                                                在cd /opt/redis-6.2.1/src  
                                                执行命令：      
                                                        redis-cli -c -p 6379 -h 192.168.40.129
                                                查看集群节点得信息：
                                                        cluster nodes
                                        
                                        slot:
                                                一个redis集群包含16384个插槽，数据库中得每个键都属于这16384个插槽得其中一个


                                        jedis 操作redis 集群

                                                 Set<HostAndPort> set = new HashSet<HostAndPort>();
                                                set.add(new HostAndPort("192.168.40.129",6379));
                                                JedisCluster jedisCluster = new JedisCluster(set);
                                                jedisCluster.set("k1","v1");
                                                System.out.println(jedisCluster.get("k1"));

                        缓存穿透：
                                 https://blog.csdn.net/womenyiqilalala/article/details/105205532
                                现象：
                                        1.应用服务器压力变大
                                        2.Redis命中率降低
                                        3.一直查询数据库
                                导致：
                                        1.redis查不到数据
                                        2.出现很多不正常得url  -> 黑客攻击

                                       就是穿透了Redis 直接查询数据库，访问的还是虚假得url，导致服务器崩溃      
                                
                                解决方案：
                                        一个一定不存在得缓存及查询不到的数据，由于缓存是不命中时被动写得，并且处于容错考虑，如果从存储层
                                        查询不到数据则不写入缓存，这将导致这个不存在得数据每次请求都要到存储层去查询，失去了缓存得意义

                                        解决：
                                        1.对空值缓存：
                                                如果一个查询返回的数据为空（不管数据是否存在），我们仍然把这个null进行缓存。设置空结果过期时间
                                                很短，最长不超过五分钟
                                        2.设置可访问得白名单
                                                使用bitmap类型定义一个可以访问得名单，名单id作为bitmaps偏移量，每次访问和bitmap里得值
                                                进行比较，如果访问id不在bitmap中，进行拦截不许访问。
                                        3.进行实时监控
                                                发现Redis命中率开始急速下降，需要排查访问对象和访问的数据，设置黑名单限制服务
                        缓存击穿：
                                现象：
                                        1.数据库访问压力瞬时变大
                                        2.redis里没有出现大量key过期
                                        3.redis正常运行
                                原因：
                                        1.redis 某个key过期了，然后还有大量访问这个key ，导致大量请求访问数据库
                                解决方案：      
                                        1.预先设置热门数据：
                                                在redis高峰期前，把一些热门数据提前存入reids里，加大这些数据key得时常
                                        2.实时调整
                                                现场调整设置过期时常
                                        3.使用分布式互斥锁
                                                1）在缓存失效时候判断拿出来的是不是null，不是null去load db 重建缓存
                                                2) 只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可     
                        
                        缓存雪崩：
                                原因：
                                        由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不可用（宕机）或者大量缓存由
                                        于超时时间相同在同一时间段失效（大批key失效/热点数据失效），大量请求直接到达存储层，存储层压力过大导
                                        致系统雪崩。

                                解决方案：
                                       1.
                                        可以把缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务。利用sentinel或cluster实现。
                                        采用多级缓存，本地进程作为一级缓存，redis作为二级缓存，不同级别的缓存设置的超时时间不同，即使某级缓存过期了，也有其他级别缓存兜底
                                        缓存的过期时间用随机值，尽量让不同的key的过期时间不同（例如：定时任务新建大批量key，设置的过期时间相同）
                                       2.使用锁或队列
                                       3.设置过期标志更新缓存：
                                                记录缓存数据过期时间，提前处理，快过期触发别的线程在后台更新缓存
                                       4.将缓存失效期分散开
                                                在原有的失效时间上增加一个随机值，比如1-5分钟随机，这样每一个缓存过期时间得重复率就会降低
                                                就很难引发集体失效      

                        分布式锁：
                                各个分布式模块之间JVM无法协调，这时采用Redis作为分布式锁

                                使用setnx 上锁    expire 设置过期时间   del 删除锁
                                setnx key  val   设置key val 如果key 不在就创建 key 在就什么都不做

                                缺点：
                                        上锁之后没来的及设置过期时间就出问题了
                                解决方案：      
                                        set keyname nx ex 时间    nx 就是采用setnx 形式上锁  ex是设置过期时间 一条语句设置完
                                
                                坑1：
                                        如果分布式系统A获取锁 然后出现于异常系统自动是方便锁这时B获取锁   然后A恢复了，释放了B的锁

                                        解决：  给每一个系统添加唯一的锁UUID 并且在释放锁时候判断一下是不是自己的就可以了