Redis 大厂学院

    查看redis 版本 redis-server -v 或者 redis-cli 进入交互界面 info

    启动:
                                cd /usr/local/bin
                                redis-server /opt/redisconf/redis.conf
                  
    Redis 最大的问题就是内存大小和网络IO问题而不是CPU的问题 

            redis 单机 CP
            redis 集群 Ap 

    reids 1-3版本为单线程
          4 单多都有 负责处理客户端请求的线程是单线程 多线程删除
          6 为多线程 多线程IO 工作线程为单线程（打命令） 总体是多线程

            Redis 6.0 将网络数据读写、请求协议解析通过多个IO线程的来处理 ，
            对于真正的命令执行来说，仍然使用主线程操作
        
        单线程的好处：
 
            1 使用单线程模型是 Redis 的开发和维护更简单，因为单线程模型方便开发和调试；
             
            2 即使使用单线程模型也并发的处理多客户端的请求，主要使用的是多路复用和非阻塞 IO；
             
            3 对于 Redis 系统来说，主要的性能瓶颈是内存或者网络带宽而并非 CPU。 ************************
            
            4.数据结构简单

        为什么引入多线程：
        
            3-4时 如果删除特别大的key可能会阻塞

            6  IO多路复用（默认关闭）
        
            比如当我（Redis）需要删除一个很大的数据时，因为是单线程同步操作，这就会导致 Redis 服务卡顿，
            于是在 Redis 4.0 中就新增了多线程的模块，当然此版本中的多线程主要是为了解决删除数据效率比较低的问题的。
             unlink key    flushdb async    flushall async  把删除工作交给了后台的小弟（子线程）异步来删除数据了。

            unlink 删除 e.g.  set k1 v1    unlink k1 这样就异步删除了（创建一个线程）

        redis 一定要安装到linux unix 因为unix系统支持 select epoll poll 可以发挥极致性能

        IO多路复用：（来活了通知你再干）
            这是IO模型的一种，即经典的Reactor设计模式，
            I/O 多路复用，简单来说就是通过监测文件的读写事件再通知线程执行相关操作，保证 Redis 的非阻塞 I/O 能够顺利执行完成的机制。
            多路指的是多个socket连接，
            复用指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。
 
            epoll是最新的也是目前最好的多路复用技术。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗）
            ，且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。

            在 Redis 6.0 中新增了多线程的功能来提高 I/O 的读写性能，他的主要实现思路是将主线程的 IO 读写任务拆分给一组独立的线程
            去执行，这样就可以使多个 socket 的读写可以并行化了，采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减
            少网络IO的时间消耗），将最耗时的Socket的读取、请求解析、写入单独外包出去，剩下的命令执行仍然由主线程串行执行并和内存的
            数据交互。

        布隆过滤器：
            一个不是1就是0的二进制数组 默认都是0
            判断一个值是否在一个大数据集合中，有一定错误率，判断出有是很有可能有，没有是一定没有
            只能加数据不能删数据，删数据会增加误判率，误判只会发生再没有添加过的元素上

            如何触发误判：
                由于哈希值误判，例如存入刘备 hash = 1 关羽 hash = 2 张飞 hash = 3
                然后判断吕布是否在集合中，计算出吕布hash值是3，这就是误判，判断有实际没有
                但是要是是已经存在的元素 一定不会发生误判 因为计算出的hash位置上就是他自己。
            hash冲突案例：
                “Aa” 和 “BB”  java 里
            为什么不能删数据;
                因为布隆过滤器有多个hash函数，计算出多个位置，删除一个可能误删别人的
                e.g. 刘备 存入hash 1 5 6 位置
                     张飞 存入hash 3 5 8 位置 
                     删除刘备 1 5 6全没了  这样张飞的5也没了就容易报错  
            误判率越小占用坑位越多越消耗性能
            

        便利所有 0 -1

        String:
            统计点赞 incr
        Hash:
            存对象 存商品信息 或者存 kv 信息 都可以 网址长短链接映射存储
        List:
            双向链表 queue stack ，存实时评论，实时点赞信息，商品评论信息
            一对多的分页，分楼层展示
        Set:
            抽奖 spop srandmember
            qq可能认识的人,数学集合计算 sdiff sinter sunion
            微信朋友圈点赞，去除重复，不能有重复的时候
        Zset:
            根据商品热度排序 zrangebyscore 
            热搜
            访问量很大总改变的时候 排序+分页统计 不可以用list 数据变动大 必须用zset score记录时间 value记录账户信息

        bitmap:    记录具体是谁   二值统计
            所有打卡，记录登录信息
            查看连续登录信息 bittop
            某用户一年登录次数 bitcount
            连续两天登录的用户的信息 （一个表记录用户信息和下标信息，一个bitmap 记录一天登录信息 两个进行bittop ）
            也可以做数据去重，用户去重操作 反正不是0就是1

        hyperloglog: 16384个草     计数（不记人）
            所有计数，不计算重复，错误率 0.81%  -》 1.04/sqrt(16384) = 0.08125
            UV统计 独立访客 同一个人进两次也只记一次
            DAU 日常活跃用户统计 需要去重
            只查不存
            
        geo:
            地图，约炮，美团

        布隆过滤器：  查找
            缓存穿透，黑名单校验,白名单校验
            主要功能用于判断一个元素是否在集合中（适合亿万数据查找一个，只查不存）
            防止缓存穿透吧
            可以用于防止抖音推荐重复视频，推荐过的加入bloomFilter
    



        String：   512M
            set get 
        Hash: 2^32 -1
            hset hget  hgetall
        List :
            Lpush lpop
        Set:
            sadd scard sdiff sinter sunion spop
        Zset:
            zadd zrange zrangebyscore zincrby 

        bitmap:   string                
                setbit getbit bitcount bittop (两个bitmap位置映射 或运算)
        hyperloglog   string
                pfadd pfcount 
        geo:  zset
                geoadd geopos（返回坐标） geohash(返回hash) georadius（给定坐标附近）  可以用zset zrange 便利



        缓存雪崩：
            sentinel hytrix 高可用+集群 过期时间加随机值
        缓存穿透：
            设置空值存进redis bloomfilter(不存数据，只是记录)
        缓存击穿：
            互斥更新(双端检索+sync)，随机退避，差异失效时间


        热点击穿问题解决：
            比如淘宝有一组热点货物，使用redis list存储现在这一组数据到点了该下架了需要更新一组新的货物
            我更新什么东西,首先执行删除再执行增加，这里这两个操作中间有一定量的间隔，如果这个时候有人来请求数据，就会造成缓存击穿
            怎么解决呢？
                设置一主一丛redis  不是slaveof那个 两个完全独立的redis 主A 丛 b
                查询时候先查 A 再查 B
    
                更新的时候先 B 再更新 A 并且 B过期时间设置比A长

        分布式锁：（必须redis集群才可以使用）
            五大要素 ： 独占 高可用 防死锁 不乱抢 重入性 
            
            自己实现需要考虑的因素：
                加锁设置锁时间时要原子性 时间保证宕机也没事  ---set key nx ex time
                放锁要在 finally 并且判断这个锁是不是自己的还要保证原子性 ---lua脚本 获取锁时候判断一下value是不是自己的
                需要保证时间足够，不够得有看门狗给加时间 --采用redission 看门狗
            实现方法：
                RedLock算法实现 的Redission 
                使用Redssion也需要判断一下锁是不是当前线程的，在QPS极高的情况下容易出EXCEPTION

                
            对于redis要求：
                单机redis   不行，主机宕机完了
                普通集群 master-slaver   redis异步复制造成的锁丢失，比如：主节点没来的及把刚刚set进来这条数据给从节点，就挂了。
                RedLock解决： 
                    多个机器 单数个 都是master 不同步 采用多主模式
                    不要异步同步出现锁丢失，而是全部master 全部负责一起获得
                    Redlock 存的是一个hash 名字是你自定义的
                    Redlock 里面上锁 开锁 自动保证 原子性

           RedLock 缓存续命：
               
                获取锁成功后，给锁加一个watchdog ， 通过异步(futher)额外起一个线程，定期查看是否还持有锁，如果有就延长锁的寿命
            （每1/3锁的时间检查一次）默认情况下没有自己指定超时时间，就设置锁超时时间为30s（默认的）,所以每10s(30/3)检查一次 每次续约30s
                直到你主线程工作结束，才会结束
            
            RedLock原理：
                看门狗 + 三段lua脚本（加锁）（解锁）

                三段lua脚本 （加锁）：
                    第一段 头一次来加锁
                    第二段 可重入锁 锁+1
                    第三段 锁不是当前线程，释放锁

                三段lua脚本 （解锁）：
                    第一段 释放锁线程和已经存在锁的线程不是一个 返回null
                    第二段 先开一次锁，剩余次数>0，说明可重入，刷新时间
                    第三段 次数<0删除key 发消息告诉锁没了

        redis lua:
            保证操作原子性的操作 


        redis lru:
            过期淘汰策略
        
        redis 内存相关
            查看redis 内存大小 config get maxmemory
            设置redis 内存大小 config set maxmemory num
            查看redis 内存使用情况 info memory 

            redis 内存如果不设置大小默认为0 就是说默认不限制大小

            三种过期淘汰策略：
                1.立刻删除  对cpu不好 对内存好
                2.惰性删除  key过期了，下次访问时候删除 对内存不友好 对cpu友好
                3.定期删除  定期随机访问 随机删除
            
            redis缓存淘汰策略 8种
                四个方面：
                    lru   淘汰最近最久没使用的
                    lfu   淘汰最近使用频率最低的
                    ttl   直接删
                    random 随机

                两个维度：
                    过期中筛选
                    所有中筛选


        redis 五大数据类型：
            String   --->  SDS  
            Hash   ---> ziplist / hashtable     key 数量<512 并且 单个key长度都 <=64 byte  ziplist    否则 hashatble
            List   ---> linkedlist/ziplist (redis6之前)   quicklist (redis6)
            Set   ---> intset/hashtable    存的是 int 并且 个数小于阈值(3) intset  否则 hashatble
            Zset   ---> ziplist/skiplist  元素总个数 < 128 并且 单个元素长度 <= 64 ziplist 否则 skiplist
            bitmap   ---> String 
            htperloglog   ---> String 
            GEO   ---> zset

            RedisObject：
                包含以下几个东西：
                type : 对象种类
                enconding ：编码类型
                lru:采用lru清除内存中的对象
                refcount: 引用计数法 计数
                prv: 指向底层真正数据结构的指针
                
            prv:
                SDS: redis 自己封装的string 
                    结构：
                        len:已用长度
                        alloc: 最大长度
                        flags: 类型
                        buff: 实际字符串数组 char[]     c里字符串数组是用 "/0"结尾，会有问题 这里记录了长度就不会有问题
                    类型：
                        int 存的是 小于 2^63的long数字 直接写在RedisObject的pre里，不额外指向空间 int 小于 10000会从一个共享池中取数据
                        embstr 嵌入式string 内存和 redisobject 连接在一块 长度小于44时为这个类型 节省空间
                        raw: 大于44的字符，或者embstr类型的字符被改动了就会变成raw 这时内存和redisObject 分来过
                

                ziplist: 压缩链表
                        1.没有维护指针，通过推算长度来计算位置
                        2.牺牲读取速度节约空间
                        3.在内存中存储的是连续的内存空间
                        4.压缩列表是 Redis 为节约空间而实现的一系列特殊编码的连续内存块组成的顺序型数据结构，本质上是字节数组

                    结构：
                        zlbytes(占用字节数)-->zltail(尾节点偏移量) -->zlen(节点数量)-->  。。。。。(节点) -->zlend(尾节点标志)

                        每一个节点中记录了 上一个链表的长度，当前链表的长度，具体的值


                hashtable:
                    底层是通过 数组 + 链表来实现的 类似 java hashmap 1.7
                

                quicklist:(redis 6之后)
                    底层是一个linkedlist 和一个ziplist 实现 ，类似一个AQS
                    linkedlist为主体，每一个Node节点里封装了一个ziplist

                    ziplist --->   ziplist----->  ziplist


                intset:
                        整型数组
                
                skiplist:
                        1.多级索引组成的 linkedlist 类似一个二叉排序树  B+树
                        2.可以实现二分查找
                        3.跳表是一个最典型的空间换时间解决方案，而且只有在数据量较大的情况下才能体现出来优势。而且应该是
                          多写少的情况下才能使用，所以它的适用范围应该还是比较有限的
                        4.维护成本相对要高 - 新增或者删除时需要把所有索引都更新一遍；
                        5.最后在新增和删除的过程中的更新，时间复杂度也是O(log n)

                        node1 ------------------------------------------------->  node5
                          \|/                                                      \|/
                        node1 -------------------------> node3-----------------> ndoe5
                          \|/                              \|/                     \|/
                        node1 -------> node2 --------->  node3-----> nonde4----> node5

                        


        IO多路复用： 

            https://blog.csdn.net/daaikuaichuan/article/details/88735256

            https://segmentfault.com/a/1190000003063859

            第一种选择：按顺序逐个验收，先验收A，然后是B，之后是C、D。。。这中间如果有一个学生卡住，全班都会被耽误,
                       你用循环挨个处理socket，根本不具有并发能力。  BIO
 
            第二种选择：你创建30个分身线程，每个分身线程检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个
                       进程或者线程处理连接。 NIO
            
            第三种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答
                       案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。这种就是IO复用模型。Linux下的
                       select、poll和epoll就是干这个的。     IO多路复用
            
            多路复用就是指多个socket同时访问一个线程

            这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程

            NIO：
                无限循环，便利所有socket 通过这种方式查看谁要执行动作 太消耗资源

            select: 复杂度O(N) 阻塞
                select 把NIO中用户态需要拷贝的fd数组，拷贝到了内核态去执行，创建一个bitmap数组，select 记录谁要有执行的动作
                然后再次便利所有 socket ,结合bitmap数组找到谁需要执行，然后就执行。
                缺点 1.bitmap有限制 1024，
                     2.并且 每次调用select都需要拷贝数据 
                     3.bitmap 数组不能复用
                     4.select 并没有通知用户态哪一个socket有数据，仍然需要O(n)的遍历

            poll: 复杂度 O(N)  阻塞
                类似select 改进了bitmap 为一个数组 最大sicket连接数无上限，缺点还是需要拷贝数据 还是不知道具体哪个要执行动作
                缺点：1、pollfds数组拷贝到了内核态，仍然有开销
                      2、poll并没有通知用户态哪一个socket有数据，仍然需要O(n)的遍历

            epoll:  unix 复杂度 O(1) 非阻塞
                分为三步调用，
                epoll_create -----> new 一个 epoll容器 根据 socket连接数
                epoll_ctl   -------> 添加/修改/删除 要监控的文件描述符 修改红黑树
                epoll_wait --------> 发起类似select() 调用 根据事件触发 写入就绪链表 返回就绪个数int

                1.一次生命周期中只有一次从用户态拷贝到内核态的过程
                2.使用event事件通知机制，每次socket有数据会主动添加到内核，并加入就序列表中，不需要便利所有的socket

                流程：
                    1.当有socket要执行的时候，会把相应的fd置位，这里的置位是会把相应的fd放到就绪队列首部，然后再返回有几个要执行的
                      socket数量
                    2.根据数量，去遍历就绪链表头部数据，就不便利所有的了，这样时间复杂度为O(1)
                    3.有socket 就加入 就绪队列 这样很方便
                
                白话：
                    你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答
                       案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。这种就是IO复用模型


            （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用
                epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链
                表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合
                ，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

            （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要
                 一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只
                 是一个epoll内部定义的等待队列）。这也能节省不少的开销


            












